{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "few-shot learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fOL7fTUWOrT",
        "outputId": "30840f0f-5d8d-47a4-c9b6-69d3b2bb0551"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/hgg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/hgg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRWa0fBtWVsK"
      },
      "source": [
        "!mkdir data\n",
        "!cp hgg/MyDrive/WQE/data/*.npy ./data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7_0aFEMWvTf"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RCup_D5L5-w"
      },
      "source": [
        "### Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnekpzhtYIEm"
      },
      "source": [
        "train_cancers = [\"BLCA\", \"BRCA\", \"COAD\", \"ESCA\", \"HNSC\", \"KIRC\", \"KIRP\", \"LIHC\", \"LUAD\", \"LUSC\", \"PRAD\", \"THCA\", \"UCEC\"]\n",
        "isFirst = True\n",
        "for i in train_cancers:\n",
        "    data = np.load(\"data/\"+i+\"_m.npy\")\n",
        "    if isFirst:\n",
        "        all_data = data\n",
        "        isFirst = False\n",
        "    else:\n",
        "        all_data = np.concatenate((all_data, data), axis=1)\n",
        "all_x = np.transpose(all_data) #(6203, 4861)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvJu4uDAp9XP"
      },
      "source": [
        "all_y = np.load(\"data/onehot_labels.npy\")\n",
        "y_tissue = np.array([np.where(i==1)[0][0] for i in all_y[:,:-2]])\n",
        "y_type = np.array([np.where(i==1)[0][0] for i in all_y[:,-2:]])\n",
        "all_y = np.array([(y_tissue[i], y_type[i]) for i in range(len(all_x))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOIrOgBi2Qqq"
      },
      "source": [
        "train_x, validate_x, train_y, validate_y = train_test_split(all_x, all_y, test_size=0.25, random_state=8) #(4652, 4861) (1551, 4861)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcQfwOGmjq3Z"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        \n",
        "        assert(len(X) == len(Y))\n",
        "        self.length = len(X)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.Y[i]\n",
        "    \n",
        "    def collate_fn(batch):\n",
        "        batch_x = [x for x,y in batch]\n",
        "        batch_y = [y for x,y in batch]\n",
        "        \n",
        "        batch_x = torch.as_tensor(batch_x)\n",
        "        batch_y = torch.as_tensor(batch_y)\n",
        "        \n",
        "        return batch_x, batch_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSTMpzKjkETh"
      },
      "source": [
        "train_data = Dataset(train_x, train_y)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "\n",
        "for i, (data, target) in enumerate(train_dataloader):\n",
        "    print(\"Batch\", i, \":\\n\", data.shape, \"\\n\", target.shape)\n",
        "    print(target)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr5zRE_TkNys"
      },
      "source": [
        "validate_data = Dataset(validate_x, validate_y)\n",
        "validate_dataloader = torch.utils.data.DataLoader(validate_data, batch_size=8, shuffle=False)\n",
        "\n",
        "for i, (data, target) in enumerate(validate_dataloader):\n",
        "    print(\"Batch\", i, \":\\n\", data.shape, \"\\n\", target.shape)\n",
        "    print(target)\n",
        "    print(data)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6-6_O9nL-BF"
      },
      "source": [
        "### DNN pretraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XKyd5RHksUS"
      },
      "source": [
        "class MLP4(nn.Module):\n",
        "    def __init__(self, feat_in = 4861, tissue_num = 13, type_num = 2, hidden = [256, 256, 128]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc1 = nn.Linear(feat_in, hidden[0])\n",
        "        self.fc2 = nn.Linear(hidden[0], hidden[1])\n",
        "        self.fc3 = nn.Linear(hidden[1], hidden[2])\n",
        "        self.fc4_tissue = nn.Linear(hidden[2], tissue_num)\n",
        "        self.fc4_type = nn.Linear(hidden[2], type_num)\n",
        "\n",
        "        self.actv1 = nn.Sequential(nn.BatchNorm1d(hidden[0]), nn.ReLU(), nn.Dropout(0.5))\n",
        "        self.actv2 = nn.Sequential(nn.BatchNorm1d(hidden[1]), nn.ReLU(), nn.Dropout(0.5))\n",
        "        self.actv3 = nn.Sequential(nn.BatchNorm1d(hidden[2]), nn.ReLU(), nn.Dropout(0.5))\n",
        "        self.actv4 = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.actv1(self.fc1(x))\n",
        "        x = self.actv2(self.fc2(x))\n",
        "        x = self.actv3(self.fc3(x))\n",
        "        x_tissue = self.actv4(self.fc4_tissue(x))\n",
        "        x_type = self.actv4(self.fc4_type(x))\n",
        "        \n",
        "        return x_tissue, x_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXlBE9iEkF1X"
      },
      "source": [
        "def test_model_final(model, test_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss_tissue = 0.0\n",
        "        correct, total = 0, 0\n",
        "        isFirst = True\n",
        "\n",
        "        for i, data in enumerate(test_loader):\n",
        "            inputs, labels = data\n",
        "            tissue_labels = torch.tensor([label[0] for label in labels])\n",
        "            type_labels = torch.tensor([label[1] for label in labels])\n",
        "\n",
        "            inputs = inputs.float().to(\"cuda:0\")\n",
        "            tissue_labels = tissue_labels.to(\"cuda:0\")\n",
        "            type_labels = type_labels.to(\"cuda:0\")\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss1 = criterion(outputs[0], tissue_labels)\n",
        "            loss2 = criterion(outputs[1], type_labels)\n",
        "            loss = loss1 + loss2\n",
        "            running_loss_tissue += loss\n",
        "\n",
        "            total += labels.size(0)\n",
        "            _, tissue_pred = torch.max(outputs[0].data, 1)\n",
        "            _, type_pred = torch.max(outputs[1].data, 1)\n",
        "            tissue_acc = tissue_pred.eq(tissue_labels.data).cpu()\n",
        "            type_acc = type_pred.eq(type_labels.data).cpu()\n",
        "            all_acc = torch.tensor([tissue_acc[i]*type_acc[i] for i in range(len(tissue_acc))]).sum().item()\n",
        "            correct += all_acc\n",
        "\n",
        "            pred = torch.tensor([tissue_pred[i]*(type_pred[i]+1) for i in range(len(tissue_acc))])\n",
        "            true = torch.tensor([tissue_labels[i]*(type_labels[i]+1) for i in range(len(tissue_acc))])\n",
        "\n",
        "            if isFirst:\n",
        "                pred_all = pred\n",
        "                true_all = true\n",
        "                tissue_labels_all = tissue_labels\n",
        "                type_labels_all = type_labels\n",
        "                tissue_pred_all = tissue_pred\n",
        "                type_pred_all = type_pred\n",
        "\n",
        "                isFirst = False\n",
        "            else:\n",
        "                pred_all = torch.cat((pred_all, pred), 0)\n",
        "                true_all = torch.cat((true_all, true), 0)\n",
        "                tissue_labels_all = torch.cat((tissue_labels_all, tissue_labels), 0)\n",
        "                type_labels_all = torch.cat((type_labels_all, type_labels), 0)\n",
        "                tissue_pred_all = torch.cat((tissue_pred_all, tissue_pred), 0)\n",
        "                type_pred_all = torch.cat((type_pred_all, type_pred), 0)\n",
        "\n",
        "\n",
        "        p_r_f = precision_recall_fscore_support(true_all, pred_all, average=None, labels=np.unique(pred_all))[:3]\n",
        "        print(tissue_labels_all, type_labels_all)\n",
        "        print(tissue_pred_all, type_pred_all)\n",
        "        print(np.unique(pred_all))\n",
        "        print(p_r_f)\n",
        "\n",
        "        running_loss_tissue /= len(test_loader)\n",
        "        print('Validating Loss (tissue):', running_loss_tissue, 'Acc:', correct/total)\n",
        "        return running_loss_tissue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpA4JPyp_tfJ"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "net = MLP4()\n",
        "net = net.to(device).float()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5000):  # loop over the dataset multiple times\n",
        "    net.train()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        inputs, labels = data\n",
        "        tissue_labels = torch.tensor([label[0] for label in labels])\n",
        "        type_labels = torch.tensor([label[1] for label in labels])\n",
        "\n",
        "        inputs = inputs.float().to(\"cuda:0\")\n",
        "        tissue_labels = tissue_labels.to(\"cuda:0\")\n",
        "        type_labels = type_labels.to(\"cuda:0\")\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        \n",
        "        loss1 = criterion(outputs[0], tissue_labels)\n",
        "        loss2 = criterion(outputs[1], type_labels)\n",
        "        loss = loss1 + loss2\n",
        "\n",
        "        total += labels.size(0)\n",
        "        _, tissue_pred = torch.max(outputs[0].data, 1)\n",
        "        _, type_pred = torch.max(outputs[1].data, 1)\n",
        "        tissue_acc = tissue_pred.eq(tissue_labels.data).cpu()\n",
        "        type_acc = type_pred.eq(type_labels.data).cpu()\n",
        "        all_acc = torch.tensor([tissue_acc[i]*type_acc[i] for i in range(len(tissue_acc))]).sum().item()\n",
        "        correct += all_acc\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % len(train_dataloader) == len(train_dataloader)-1:\n",
        "            print('[%d, %5d] tissue loss: %.3f' %\n",
        "                (epoch + 1, i + 1, running_loss / len(train_dataloader)), 'Acc:', correct/total)\n",
        "            running_loss = 0.0\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        test_model_final(net, validate_dataloader, nn.CrossEntropyLoss())\n",
        "    if epoch % 100 == 0:\n",
        "        print(\"Save model...\")\n",
        "        torch.save(net, \"./hgg/MyDrive/model_3.pt\")\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTfckVb5MOrG"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPhkA4xu7jht"
      },
      "source": [
        "#test_y = [i[1] for i in test_y]\n",
        "support_x, query_x, support_y, query_y = train_test_split(test_x, test_y, test_size=0.5, random_state=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwKTFkOf_gcv"
      },
      "source": [
        "query_data = Dataset(query_x, query_y)\n",
        "query_dataloader = torch.utils.data.DataLoader(query_data, batch_size=100, shuffle=False)\n",
        "\n",
        "for i, (data, target) in enumerate(query_dataloader):\n",
        "    print(\"Batch\", i, \":\\n\", data.shape, \"\\n\", target.shape)\n",
        "    print(target)\n",
        "    print(data)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJa6Bkc8oTuI"
      },
      "source": [
        "support_data = Dataset(support_x, support_y)\n",
        "support_dataloader = torch.utils.data.DataLoader(support_data, batch_size=100, shuffle=False)\n",
        "\n",
        "for i, (data, target) in enumerate(support_dataloader):\n",
        "    print(\"Batch\", i, \":\\n\", data.shape, \"\\n\", target.shape)\n",
        "    print(target)\n",
        "    print(data)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGzvgFoe0X6b"
      },
      "source": [
        "### Few shot learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhYI-AkY0dVW"
      },
      "source": [
        "# Load pre-trained model\n",
        "net = torch.load(\"./hgg/MyDrive/model3.pt\")\n",
        "state = net.state_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPNQhniKoXct"
      },
      "source": [
        "class MLP5(nn.Module):\n",
        "    def __init__(self, feat_in = 4861, tissue_num = 13, type_num = 2, hidden = [256, 256, 128]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc1 = nn.Linear(feat_in, hidden[0])\n",
        "        self.fc2 = nn.Linear(hidden[0], hidden[1])\n",
        "        self.fc3 = nn.Linear(hidden[1], hidden[2])\n",
        "        self.fc4_tissue = nn.Linear(hidden[2], tissue_num)\n",
        "        self.fc4_type = nn.Linear(hidden[2], type_num)\n",
        "\n",
        "        self.actv1 = nn.Sequential(nn.BatchNorm1d(hidden[0]), nn.ReLU(), nn.Dropout(0.5))\n",
        "        self.actv2 = nn.Sequential(nn.BatchNorm1d(hidden[1]), nn.ReLU(), nn.Dropout(0.5))\n",
        "        self.actv3 = nn.Sequential(nn.BatchNorm1d(hidden[2]), nn.ReLU(), nn.Dropout(0.5))\n",
        "        self.actv4 = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.actv1(self.fc1(x))\n",
        "        x = self.actv2(self.fc2(x))\n",
        "        x = self.actv3(self.fc3(x))\n",
        "        x_tissue = self.actv4(self.fc4_tissue(x))\n",
        "        x_type = self.actv4(self.fc4_type(x))\n",
        "\n",
        "        return x_tissue, x_type\n",
        "\n",
        "    def features(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.actv1(self.fc1(x))\n",
        "        x = self.actv2(self.fc2(x))\n",
        "        x = self.actv3(self.fc3(x))\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTQ_Ip44Mve3"
      },
      "source": [
        "def test_model(model, test_loader, criterion, z_proto_tissue, z_proto_type, best_acc):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss_tissue = 0.0\n",
        "        correct, total = 0, 0\n",
        "        isFirst = True\n",
        "\n",
        "        for i, data in enumerate(test_loader):\n",
        "            inputs, labels = data\n",
        "            tissue_labels = torch.tensor([label[0] for label in labels]).to(device)\n",
        "            type_labels = torch.tensor([label[1] for label in labels]).to(device)\n",
        "            inputs = inputs.float().to(device)\n",
        "\n",
        "            z_query = model.features(inputs)\n",
        "\n",
        "            tissue_dists = torch.cdist(z_query, z_proto_tissue)\n",
        "            type_dists = torch.cdist(z_query, z_proto_type)\n",
        "            tissue_scores = -tissue_dists\n",
        "            type_scores = -type_dists\n",
        "\n",
        "            loss1 = criterion(tissue_scores, tissue_labels)\n",
        "            loss2 = criterion(type_scores, type_labels)\n",
        "            loss = loss1 + loss2\n",
        "            running_loss_tissue += loss.item()\n",
        "\n",
        "            total += labels.size(0)\n",
        "            _, tissue_pred = torch.max(tissue_scores.data, 1)\n",
        "            _, type_pred = torch.max(type_scores.data, 1)\n",
        "            tissue_acc = tissue_pred.eq(tissue_labels.data).cpu()\n",
        "            type_acc = type_pred.eq(type_labels.data).cpu()\n",
        "            all_acc = torch.tensor([tissue_acc[i]*type_acc[i] for i in range(len(tissue_acc))]).sum().item()\n",
        "            correct += all_acc\n",
        "\n",
        "            pred = torch.tensor([tissue_pred[i]*10+type_pred[i] for i in range(len(tissue_acc))])\n",
        "            true = torch.tensor([tissue_labels[i]*10+type_labels[i] for i in range(len(tissue_acc))])\n",
        "\n",
        "            if isFirst:\n",
        "                pred_all = pred\n",
        "                true_all = true\n",
        "                tissue_labels_all = tissue_labels\n",
        "                type_labels_all = type_labels\n",
        "                tissue_pred_all = tissue_pred\n",
        "                type_pred_all = type_pred\n",
        "\n",
        "                isFirst = False\n",
        "            else:\n",
        "                pred_all = torch.cat((pred_all, pred), 0)\n",
        "                true_all = torch.cat((true_all, true), 0)\n",
        "                tissue_labels_all = torch.cat((tissue_labels_all, tissue_labels), 0)\n",
        "                type_labels_all = torch.cat((type_labels_all, type_labels), 0)\n",
        "                tissue_pred_all = torch.cat((tissue_pred_all, tissue_pred), 0)\n",
        "                type_pred_all = torch.cat((type_pred_all, type_pred), 0)\n",
        "\n",
        "\n",
        "        p_r_f = precision_recall_fscore_support(true_all, pred_all, average=None, labels=np.unique(pred_all))[:3]\n",
        "        # print(tissue_labels_all, type_labels_all)\n",
        "        # print(tissue_pred_all, type_pred_all)\n",
        "        print(np.unique(pred_all))\n",
        "        print(np.array(p_r_f))\n",
        "\n",
        "        running_loss_tissue /= len(test_loader)\n",
        "        print('-------------------------Validating Loss:', running_loss_tissue, 'Acc:', correct/total)\n",
        "\n",
        "        if correct/total > best_acc:\n",
        "            best_acc = correct/total\n",
        "            print(\"---------------------------------------------------------------Save model...\")\n",
        "            torch.save(few_shot_net, \"./hgg/MyDrive/model_fewshot.pt\")\n",
        "            print(tissue_labels_all, type_labels_all)\n",
        "            print(tissue_pred_all, type_pred_all)\n",
        "        \n",
        "        return best_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzxuQYg3Q0Uu"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "few_shot_net = MLP5()\n",
        "few_shot_net.load_state_dict(state)\n",
        "few_shot_net = few_shot_net.to(device).float()\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "#optimizer = optim.SGD(few_shot_net.parameters(), lr=0.001)\n",
        "optimizer = optim.Adam(few_shot_net.parameters(), lr=0.00001)\n",
        "\n",
        "best_acc = 0\n",
        "support_dataloader, query_dataloader = train_dataloader, validate_dataloader\n",
        "\n",
        "for epoch in range(200):  # loop over the dataset multiple times\n",
        "\n",
        "    few_shot_net.train()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "    for i, data in enumerate(support_dataloader):\n",
        "        inputs, labels = data\n",
        "        tissue_labels = torch.tensor([label[0] for label in labels]).to(device)\n",
        "        type_labels = torch.tensor([label[1] for label in labels]).to(device)\n",
        "        inputs = inputs.float().to(device)\n",
        "        # support_labels = support_labels.to(\"cuda:0\")\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        z_support = few_shot_net.features(inputs)\n",
        "\n",
        "        n_way_tissue = len(torch.unique(tissue_labels))\n",
        "        n_way_type = len(torch.unique(type_labels))\n",
        "\n",
        "        z_proto_tissue = torch.cat([z_support[torch.nonzero(tissue_labels == label)].mean(0) for label in torch.unique(tissue_labels)])\n",
        "        z_proto_type = torch.cat([z_support[torch.nonzero(type_labels == label)].mean(0) for label in torch.unique(type_labels)])\n",
        "\n",
        "        tissue_dists = torch.cdist(z_support, z_proto_tissue)\n",
        "        type_dists = torch.cdist(z_support, z_proto_type)\n",
        "        # tissue_scores = -tissue_dists\n",
        "        # type_scores = -type_dists\n",
        "        tissue_scores = (-tissue_dists).softmax(dim=1)\n",
        "        type_scores = (-type_dists).softmax(dim=1)\n",
        "\n",
        "        loss1 = criterion(tissue_scores, tissue_labels)\n",
        "        loss2 = criterion(type_scores, type_labels)\n",
        "        loss = loss1 + loss2\n",
        "        \n",
        "        total += tissue_labels.size(0)\n",
        "        _, tissue_pred = torch.max(tissue_scores.data, 1)\n",
        "        _, type_pred = torch.max(type_scores.data, 1)\n",
        "        tissue_acc = tissue_pred.eq(tissue_labels.data).cpu()\n",
        "        type_acc = type_pred.eq(type_labels.data).cpu()\n",
        "        all_acc = torch.tensor([tissue_acc[i]*type_acc[i] for i in range(len(tissue_acc))]).sum().item()\n",
        "        correct += all_acc\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % len(support_dataloader) == len(support_dataloader)-1:\n",
        "            print('[%d, %5d] training loss: %.3f'  %\n",
        "                (epoch + 1, i + 1, running_loss / len(support_dataloader)), 'Acc:', correct/total)\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "    if epoch % 3 == 0:\n",
        "        best_acc = test_model(few_shot_net, query_dataloader, nn.CrossEntropyLoss(), z_proto_tissue, z_proto_type, best_acc)\n",
        "    # if correct/total > best_acc:\n",
        "    #     best_acc = correct/total\n",
        "    #     print(\"Save model...\")\n",
        "    #     torch.save(few_shot_net, \"./hgg/MyDrive/model_fewshot.pt\")\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}